{
  "doubt": {
    "precision": 0.6,
    "recall": 0.6666666666666666,
    "f1-score": 0.631578947368421,
    "support": 9,
    "confused_with": {
      "situation_area": 1,
      "positive_belief": 1
    }
  },
  "greet": {
    "precision": 1.0,
    "recall": 0.6666666666666666,
    "f1-score": 0.8,
    "support": 3,
    "confused_with": {
      "situation_area": 1
    }
  },
  "situation": {
    "precision": 0.8,
    "recall": 0.75,
    "f1-score": 0.7741935483870969,
    "support": 16,
    "confused_with": {
      "feeling+situation": 1,
      "feeling": 1
    }
  },
  "advantages_of_acting": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "thought": 1
    }
  },
  "disagree": {
    "precision": 0.8,
    "recall": 0.8,
    "f1-score": 0.8000000000000002,
    "support": 5,
    "confused_with": {
      "agree": 1
    }
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "feeling+situation": {
    "precision": 0.875,
    "recall": 1.0,
    "f1-score": 0.9333333333333333,
    "support": 7,
    "confused_with": {}
  },
  "evidence_for": {
    "precision": 0.5,
    "recall": 0.3333333333333333,
    "f1-score": 0.4,
    "support": 3,
    "confused_with": {
      "evidence_against": 1,
      "feeling": 1
    }
  },
  "explain": {
    "precision": 0.5,
    "recall": 0.5,
    "f1-score": 0.5,
    "support": 2,
    "confused_with": {
      "doubt": 1
    }
  },
  "behavior": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "thought": 1
    }
  },
  "positive_belief": {
    "precision": 0.75,
    "recall": 0.6,
    "f1-score": 0.6666666666666665,
    "support": 5,
    "confused_with": {
      "negative_belief": 1,
      "thought": 1
    }
  },
  "negative_belief": {
    "precision": 0.7272727272727273,
    "recall": 0.8888888888888888,
    "f1-score": 0.7999999999999999,
    "support": 9,
    "confused_with": {
      "thought": 1
    }
  },
  "thought+situation": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 4,
    "confused_with": {
      "doubt": 1,
      "feeling": 1
    }
  },
  "felt_where": {
    "precision": 0.75,
    "recall": 0.75,
    "f1-score": 0.75,
    "support": 4,
    "confused_with": {
      "feeling": 1
    }
  },
  "feeling": {
    "precision": 0.8936170212765957,
    "recall": 0.8936170212765957,
    "f1-score": 0.8936170212765957,
    "support": 47,
    "confused_with": {
      "agree": 2,
      "doubt": 2
    }
  },
  "situation_area": {
    "precision": 0.7272727272727273,
    "recall": 1.0,
    "f1-score": 0.8421052631578948,
    "support": 8,
    "confused_with": {}
  },
  "telling_friend": {
    "precision": 0.8571428571428571,
    "recall": 1.0,
    "f1-score": 0.923076923076923,
    "support": 6,
    "confused_with": {}
  },
  "thought": {
    "precision": 0.7058823529411765,
    "recall": 0.7058823529411765,
    "f1-score": 0.7058823529411765,
    "support": 17,
    "confused_with": {
      "explain": 1,
      "situation": 1
    }
  },
  "interpretation": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "situation": 1
    }
  },
  "act_how": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4,
    "confused_with": {}
  },
  "agree": {
    "precision": 0.7272727272727273,
    "recall": 1.0,
    "f1-score": 0.8421052631578948,
    "support": 8,
    "confused_with": {}
  },
  "evidence_against": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4,
    "confused_with": {
      "feeling": 1,
      "telling_friend": 1,
      "situation": 1
    }
  },
  "accuracy": 0.7891566265060241,
  "macro avg": {
    "precision": 0.6460663824172186,
    "recall": 0.6388661331715147,
    "f1-score": 0.6331466357287577,
    "support": 166
  },
  "weighted avg": {
    "precision": 0.7704799718353934,
    "recall": 0.7891566265060241,
    "f1-score": 0.77359509869175,
    "support": 166
  },
  "micro avg": {
    "precision": 0.7891566265060241,
    "recall": 0.7891566265060241,
    "f1-score": 0.7891566265060241,
    "support": 166
  }
}