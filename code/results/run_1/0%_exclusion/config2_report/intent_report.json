{
  "doubt": {
    "precision": 0.6666666666666666,
    "recall": 0.2222222222222222,
    "f1-score": 0.3333333333333333,
    "support": 9,
    "confused_with": {
      "situation_area": 1,
      "situation": 1
    }
  },
  "greet": {
    "precision": 0.6666666666666666,
    "recall": 0.6666666666666666,
    "f1-score": 0.6666666666666666,
    "support": 3,
    "confused_with": {
      "situation": 1
    }
  },
  "situation": {
    "precision": 0.5555555555555556,
    "recall": 0.625,
    "f1-score": 0.5882352941176471,
    "support": 16,
    "confused_with": {
      "thought+situation": 1,
      "agree": 1
    }
  },
  "advantages_of_acting": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "positive_belief": 1
    }
  },
  "disagree": {
    "precision": 0.6,
    "recall": 0.6,
    "f1-score": 0.6,
    "support": 5,
    "confused_with": {
      "agree": 1,
      "feeling": 1
    }
  },
  "goodbye": {
    "precision": 0.6666666666666666,
    "recall": 1.0,
    "f1-score": 0.8,
    "support": 2,
    "confused_with": {}
  },
  "feeling+situation": {
    "precision": 1.0,
    "recall": 0.42857142857142855,
    "f1-score": 0.6,
    "support": 7,
    "confused_with": {
      "thought+situation": 2,
      "situation": 1
    }
  },
  "evidence_for": {
    "precision": 0.3333333333333333,
    "recall": 0.3333333333333333,
    "f1-score": 0.3333333333333333,
    "support": 3,
    "confused_with": {
      "evidence_against": 1,
      "feeling": 1
    }
  },
  "explain": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 2,
    "confused_with": {
      "telling_friend": 1
    }
  },
  "behavior": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "positive_belief": 1
    }
  },
  "positive_belief": {
    "precision": 0.2,
    "recall": 0.2,
    "f1-score": 0.20000000000000004,
    "support": 5,
    "confused_with": {
      "thought": 3,
      "telling_friend": 1
    }
  },
  "negative_belief": {
    "precision": 0.5454545454545454,
    "recall": 0.6666666666666666,
    "f1-score": 0.6,
    "support": 9,
    "confused_with": {
      "agree": 1,
      "positive_belief": 1
    }
  },
  "thought+situation": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4,
    "confused_with": {
      "situation": 2,
      "act_how": 1,
      "advantages_of_acting": 1
    }
  },
  "felt_where": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4,
    "confused_with": {}
  },
  "feeling": {
    "precision": 0.8148148148148148,
    "recall": 0.9361702127659575,
    "f1-score": 0.8712871287128713,
    "support": 47,
    "confused_with": {
      "negative_belief": 2,
      "act_how": 1
    }
  },
  "situation_area": {
    "precision": 0.7142857142857143,
    "recall": 0.625,
    "f1-score": 0.6666666666666666,
    "support": 8,
    "confused_with": {
      "feeling": 2,
      "situation": 1
    }
  },
  "telling_friend": {
    "precision": 0.75,
    "recall": 1.0,
    "f1-score": 0.8571428571428571,
    "support": 6,
    "confused_with": {}
  },
  "thought": {
    "precision": 0.6428571428571429,
    "recall": 0.5294117647058824,
    "f1-score": 0.5806451612903226,
    "support": 17,
    "confused_with": {
      "thought+situation": 2,
      "feeling": 2
    }
  },
  "interpretation": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "greet": 1
    }
  },
  "act_how": {
    "precision": 0.5714285714285714,
    "recall": 1.0,
    "f1-score": 0.7272727272727273,
    "support": 4,
    "confused_with": {}
  },
  "agree": {
    "precision": 0.5714285714285714,
    "recall": 0.5,
    "f1-score": 0.5333333333333333,
    "support": 8,
    "confused_with": {
      "feeling": 1,
      "situation_area": 1
    }
  },
  "evidence_against": {
    "precision": 0.3333333333333333,
    "recall": 0.25,
    "f1-score": 0.28571428571428575,
    "support": 4,
    "confused_with": {
      "feeling": 1,
      "situation": 1
    }
  },
  "accuracy": 0.6506024096385542,
  "macro avg": {
    "precision": 0.528749617385981,
    "recall": 0.5037746497696435,
    "f1-score": 0.49592261155685047,
    "support": 166
  },
  "weighted avg": {
    "precision": 0.655186402174354,
    "recall": 0.6506024096385542,
    "f1-score": 0.6359118435268754,
    "support": 166
  },
  "micro avg": {
    "precision": 0.6506024096385542,
    "recall": 0.6506024096385542,
    "f1-score": 0.6506024096385542,
    "support": 166
  }
}