{
  "doubt": {
    "precision": 0.75,
    "recall": 0.3333333333333333,
    "f1-score": 0.46153846153846156,
    "support": 9,
    "confused_with": {
      "thought": 3,
      "feeling": 2
    }
  },
  "greet": {
    "precision": 0.75,
    "recall": 1.0,
    "f1-score": 0.8571428571428571,
    "support": 3,
    "confused_with": {}
  },
  "situation": {
    "precision": 0.7222222222222222,
    "recall": 0.8125,
    "f1-score": 0.7647058823529411,
    "support": 16,
    "confused_with": {
      "thought": 2,
      "felt_where": 1
    }
  },
  "advantages_of_acting": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "positive_belief": 1
    }
  },
  "disagree": {
    "precision": 1.0,
    "recall": 0.8,
    "f1-score": 0.888888888888889,
    "support": 5,
    "confused_with": {
      "feeling": 1
    }
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 2,
    "confused_with": {
      "greet": 1
    }
  },
  "feeling+situation": {
    "precision": 0.8571428571428571,
    "recall": 0.8571428571428571,
    "f1-score": 0.8571428571428571,
    "support": 7,
    "confused_with": {
      "thought": 1
    }
  },
  "evidence_for": {
    "precision": 0.5,
    "recall": 0.3333333333333333,
    "f1-score": 0.4,
    "support": 3,
    "confused_with": {
      "thought": 1,
      "feeling": 1
    }
  },
  "explain": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 2,
    "confused_with": {
      "telling_friend": 1,
      "thought": 1
    }
  },
  "behavior": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "thought": 1
    }
  },
  "positive_belief": {
    "precision": 0.5,
    "recall": 0.2,
    "f1-score": 0.28571428571428575,
    "support": 5,
    "confused_with": {
      "thought": 2,
      "telling_friend": 1,
      "situation": 1
    }
  },
  "negative_belief": {
    "precision": 0.625,
    "recall": 0.5555555555555556,
    "f1-score": 0.5882352941176471,
    "support": 9,
    "confused_with": {
      "thought": 3,
      "situation": 1
    }
  },
  "thought+situation": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4,
    "confused_with": {
      "feeling": 2,
      "feeling+situation": 1,
      "evidence_for": 1
    }
  },
  "felt_where": {
    "precision": 0.5,
    "recall": 0.25,
    "f1-score": 0.3333333333333333,
    "support": 4,
    "confused_with": {
      "feeling": 2,
      "situation_area": 1
    }
  },
  "feeling": {
    "precision": 0.7735849056603774,
    "recall": 0.8723404255319149,
    "f1-score": 0.8200000000000001,
    "support": 47,
    "confused_with": {
      "negative_belief": 2,
      "thought": 2
    }
  },
  "situation_area": {
    "precision": 0.75,
    "recall": 0.75,
    "f1-score": 0.75,
    "support": 8,
    "confused_with": {
      "feeling": 1,
      "telling_friend": 1
    }
  },
  "telling_friend": {
    "precision": 0.5454545454545454,
    "recall": 1.0,
    "f1-score": 0.7058823529411764,
    "support": 6,
    "confused_with": {}
  },
  "thought": {
    "precision": 0.46875,
    "recall": 0.8823529411764706,
    "f1-score": 0.6122448979591837,
    "support": 17,
    "confused_with": {
      "feeling": 1,
      "situation": 1
    }
  },
  "interpretation": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1,
    "confused_with": {
      "evidence_against": 1
    }
  },
  "act_how": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 4,
    "confused_with": {
      "situation": 1,
      "negative_belief": 1
    }
  },
  "agree": {
    "precision": 1.0,
    "recall": 0.625,
    "f1-score": 0.7692307692307693,
    "support": 8,
    "confused_with": {
      "feeling": 1,
      "telling_friend": 1
    }
  },
  "evidence_against": {
    "precision": 0.5,
    "recall": 0.25,
    "f1-score": 0.3333333333333333,
    "support": 4,
    "confused_with": {
      "feeling": 1,
      "telling_friend": 1,
      "situation": 1
    }
  },
  "accuracy": 0.6867469879518072,
  "macro avg": {
    "precision": 0.5564615695672729,
    "recall": 0.47825265663970296,
    "f1-score": 0.4891239339558667,
    "support": 166
  },
  "weighted avg": {
    "precision": 0.6794007433392805,
    "recall": 0.6867469879518072,
    "f1-score": 0.6586245335329067,
    "support": 166
  },
  "micro avg": {
    "precision": 0.6867469879518072,
    "recall": 0.6867469879518072,
    "f1-score": 0.6867469879518072,
    "support": 166
  }
}